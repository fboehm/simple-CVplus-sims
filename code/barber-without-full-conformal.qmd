---
title: "Simple simulations"
format: gfm
jupyter: python3.10
---

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
np.random.seed(98765)

TOL = 1e-8

######################################
# Define regression algorithm (for all other methods)
######################################

def leastsq_minL2(X,Y,X1,tol=TOL):
    uX,dX,vX = np.linalg.svd(X)
    rX = (dX>=dX[0]*tol).sum()
    betahat = (vX[:rX].T/dX[:rX]).dot(uX[:,:rX].T.dot(Y))
    return X1.dot(betahat)
def compute_PIs(X,Y,X1,alpha,fit_muh_fun, min_Y, max_Y, run_full_CP=True):
    n = len(Y)
    n1 = X1.shape[0]
    ###############################
    # Naive & jackknife/jack+/jackmm
    ###############################
    
    #muh_vals = fit_muh_fun(X,Y,np.r_[X,X1])
    #resids_naive = np.abs(Y-muh_vals[:n])
    #muh_vals_testpoint = muh_vals[n:]
    #resids_LOO = np.zeros(n)
    #muh_LOO_vals_testpoint = np.zeros((n,n1))
    #for i in range(n):
    #    muh_vals_LOO = fit_muh_fun(np.delete(X,i,0),np.delete(Y,i),\
    #                               np.r_[X[i].reshape((1,-1)),X1])
    #    resids_LOO[i] = np.abs(Y[i] - muh_vals_LOO[0])
    #    muh_LOO_vals_testpoint[i] = muh_vals_LOO[1:]
    #ind_q = (np.ceil((1-alpha)*(n+1))).astype(int)

    ###############################
    # CV+
    ###############################

    K = 10
    n_K = np.floor(n/K).astype(int)
    base_inds_to_delete = np.arange(n_K).astype(int)
    resids_LKO = np.zeros(n)
    muh_LKO_vals_testpoint = np.zeros((n,n1))
    for i in range(K):
        inds_to_delete = (base_inds_to_delete + n_K*i).astype(int)
        muh_vals_LKO = fit_muh_fun(np.delete(X,inds_to_delete,0),
                                    np.delete(Y,inds_to_delete),\
                                   np.r_[X[inds_to_delete],X1])
        resids_LKO[inds_to_delete] = np.abs(Y[inds_to_delete] - muh_vals_LKO[:n_K])
        for inner_K in range(n_K):
            muh_LKO_vals_testpoint[inds_to_delete[inner_K]] = muh_vals_LKO[n_K:]
    ind_Kq = (np.ceil((1-alpha)*(n+1))).astype(int)

    ###############################
    # split conformal
    ###############################
    
    idx = np.random.permutation(n)
    n_half = int(np.floor(n/2))
    idx_train, idx_cal = idx[:n_half], idx[n_half:]
    muh_split_vals = fit_muh_fun(X[idx_train],Y[idx_train],np.r_[X[idx_cal],X1])
    resids_split = np.abs(Y[idx_cal]-muh_split_vals[:(n-n_half)])
    muh_split_vals_testpoint = muh_split_vals[(n-n_half):]
    ind_split = (np.ceil((1-alpha)*(n-n_half+1))).astype(int)

    
    ###############################
    # construct prediction intervals
    ###############################

    PIs_dict = {'naive' : pd.DataFrame(\
                    np.c_[muh_vals_testpoint - np.sort(resids_naive)[ind_q-1], \
                        muh_vals_testpoint + np.sort(resids_naive)[ind_q-1]],\
                           columns = ['lower','upper']),\
                'jackknife' : pd.DataFrame(\
                    np.c_[muh_vals_testpoint - np.sort(resids_LOO)[ind_q-1], \
                        muh_vals_testpoint + np.sort(resids_LOO)[ind_q-1]],\
                           columns = ['lower','upper']),\
                'jackknife+' : pd.DataFrame(\
                    np.c_[np.sort(muh_LOO_vals_testpoint.T - resids_LOO,axis=1).T[-ind_q], \
                        np.sort(muh_LOO_vals_testpoint.T + resids_LOO,axis=1).T[ind_q-1]],\
                           columns = ['lower','upper']),\
                'jackknife-mm' : pd.DataFrame(\
                    np.c_[muh_LOO_vals_testpoint.min(0) - np.sort(resids_LOO)[ind_q-1], \
                           muh_LOO_vals_testpoint.max(0) + np.sort(resids_LOO)[ind_q-1]],\
                           columns = ['lower','upper']),\
                'CV+' : pd.DataFrame(\
                    np.c_[np.sort(muh_LKO_vals_testpoint.T - resids_LKO,axis=1).T[-ind_Kq], \
                        np.sort(muh_LKO_vals_testpoint.T + resids_LKO,axis=1).T[ind_Kq-1]],\
                           columns = ['lower','upper']),\
                'split' : pd.DataFrame(\
                    np.c_[muh_split_vals_testpoint - np.sort(resids_split)[ind_split-1], \
                           muh_split_vals_testpoint + np.sort(resids_split)[ind_split-1]],\
                            columns = ['lower','upper'])}

    return pd.concat(PIs_dict.values(), axis=1, keys=PIs_dict.keys())
```

```{python}
# simulation
n_vals = np.array([100, 1000, 10000]) # training set size
n1 = 100 # test set size
SNR = 10
ntrial = 50
alpha = 0.1
#dim_vals = np.arange(5,205,5)
d = 1

method_names = ['naive','jackknife','jackknife+','jackknife-mm','CV+','split']
beta = np.random.normal(size=d)
beta = beta/np.sqrt((beta**2).sum()) * np.sqrt(SNR)
X1 = np.random.normal(size=(n1,d))
Y1 = X1.dot(beta) + np.random.normal(size=n1)

Y_dic = dict.fromkeys(n_vals, 0)
X_dic = dict.fromkeys(n_vals, 0)


for n in n_vals:
    results = pd.DataFrame(columns = ['itrial','d','method','coverage','width'])
    Xa = np.zeros((n,d, ntrial))
    Ya = np.zeros((n, ntrial))
    for itrial in range(ntrial):
        X = np.random.normal(size=(n,d))
        Xa[:,:, itrial] = X
        
        Y = X.dot(beta) + np.random.normal(size=n)
        Ya[:, itrial] = Y
        
        min_Y = Y.min() - 0.1 * (Y.max()-Y.min())
        max_Y = Y.max() + 0.1 * (Y.max()-Y.min())
        # store X, Y for later use with R code
        # store as numpy arrays

        
        PIs = compute_PIs(X,Y,X1,alpha,leastsq_minL2, min_Y, max_Y, run_full_CP)
        for method in method_names:
            coverage = ((PIs[method]['lower'] <= Y1)&(PIs[method]['upper'] >= Y1)).mean()
            width = (PIs[method]['upper'] - PIs[method]['lower']).mean()
            results.loc[len(results)]=[itrial,d,method,coverage,width]
    X_dic[n] = Xa
    Y_dic[n] = Ya
    results.to_csv('../results/jackknife_simulation_results-' + str(n) + '.csv',index=False)
```


```{r}
# get python objects into my R session
Xr <- py$X_dic 
Yr <- py$Y_dic
X1r <- py$X1
Y1r <- py$Y1
n_valsr <- py$n_vals
```

```{r}

```