---
title: "Simulations with a single SNP & different sample sizes"
prefer-html: true
format:
  gfm:
    toc: true
    number-sections: true
  html: 
    toc: true
    number-sections: true
    code-fold: true
    embed-resources: true
---

## Setup

First, simulate genotype data. Then, for each subject's genotype, simulate replicate traits.

```{r}
library(magrittr)
```



```{r}
set.seed(2023-04-15)
n_tr <- 10000
n_te <- 100
n <- n_tr + n_te
# n is total number of subjects
n_reps <- 50
# n_reps is number of replicates
n_snp <- 1
# n_snp is number of SNPs
# simulate genotypes matrix
geno <- matrix(sample(c(0,1,2), n*n_snp, replace=TRUE, prob=c(0.25,0.5,0.25)), nrow=n, ncol=n_snp)
# simulate phenotype
beta <- 1
y <- as.numeric(geno %*% beta) %*% t(rep(1, n_reps)) + 
    matrix(data = rnorm(n * n_reps), nrow = n, ncol = n_reps)
# prepare for splitting into training and testing
# get test subject ids
test_ids <- sample(1:n, n_te, replace = FALSE)
# organize data
dat <- tibble::as_tibble(y) %>%
    dplyr::rename_with(function(x){ num <- stringr::str_extract(x, "[0-9]+")
                                    return(paste0("pheno", num))}
                        ) %>%
    dplyr::bind_cols(geno %>% tibble::as_tibble() %>% dplyr::rename(geno = 1)) %>%
    dplyr::mutate(id = 1:n) %>% # fix this when using more than one SNP
    dplyr::mutate(in_test_set = id %in% test_ids)
# split into training and testing
training <- dat %>% dplyr::filter(!in_test_set)
testing <- dat %>% dplyr::filter(in_test_set)
testing2 <- testing %>% dplyr::mutate(fold = as.integer(NA))
# use all training with leave K out
alpha <- 0.1
```

Above, we specified the number of replicates for the simulations. We created
`r n_reps` replicate traits for the same `r n` subjects. Note that each 
subject has only `r n_snp` SNP(s). 

```{r, prep_for_python}
gg_train <- training2_pre$geno %>% as.matrix()
pp_train <- training2_pre$pheno1
gg_test <- testing2$geno %>% as.matrix()
```

## python code, adapted from Barber's code for JK+ paper

```{python, eval = TRUE}
import numpy as np
import pandas as pd

def leastsq_minL2(X,Y,X1,tol=1e-8):
    uX,dX,vX = np.linalg.svd(X)
    rX = (dX>=dX[0]*tol).sum()
    betahat = (vX[:rX].T/dX[:rX]).dot(uX[:,:rX].T.dot(Y))
    return X1.dot(betahat)

def compute_PIs(X,Y,X1,alpha = 0.1, K=10, fit_muh_fun = leastsq_minL2):
    n = len(Y)
    #n1 = X1.shape[0]
    n1 = len(X1)
    ###############################
    # CV+
    ###############################
    n_K = np.floor(n/K).astype(int)
    base_inds_to_delete = np.arange(n_K).astype(int)
    resids_LKO = np.zeros(n)
    muh_LKO_vals_testpoint = np.zeros((n,n1))
    for i in range(K):
        inds_to_delete = (base_inds_to_delete + n_K*i).astype(int)
        X0 = np.delete(X, inds_to_delete)
        X0_2d = X0[:, np.newaxis]
        Y0 = np.delete(Y, inds_to_delete)
        X0d = X[inds_to_delete]
        X0d_2d = X0d[:, np.newaxis]
        X1_2d = X1[:, np.newaxis]
        muh_vals_LKO = fit_muh_fun(X0_2d, Y0, np.r_[X0d_2d, X1_2d])
        resids_LKO[inds_to_delete] = np.abs(Y[inds_to_delete] - muh_vals_LKO[:n_K, 0])
        for inner_K in range(n_K):
            muh_LKO_vals_testpoint[inds_to_delete[inner_K]] = muh_vals_LKO[n_K:, 0]
    ind_Kq = (np.ceil((1-alpha)*(n+1))).astype(int)
    PIs_dict = {'CV+' : pd.DataFrame(\
                    np.c_[np.sort(muh_LKO_vals_testpoint.T - resids_LKO,axis=1).T[-ind_Kq], \
                        np.sort(muh_LKO_vals_testpoint.T + resids_LKO,axis=1).T[ind_Kq-1]],\
                           columns = ['lower','upper'])}
    return pd.concat(PIs_dict.values(), axis=1, keys=PIs_dict.keys())
```

```{python, eval = FALSE}
# simulation
# simulation
n_vals = np.array([100, 1000, 10000, 100000]) # training set size
n1 = 100 # test set size
SNR = 10
ntrial = 50
alpha = 0.1
#dim_vals = np.arange(5,205,5)
d = 1
beta = np.random.normal(size=d)
beta = beta/np.sqrt((beta**2).sum()) * np.sqrt(SNR)
X1 = np.random.normal(size=(n1,d))
Y1 = X1.dot(beta) + np.random.normal(size=n1)
method = 'CV+'
# define new objects for storing Y and X
Y_dic = dict.fromkeys(n_vals, 0)
X_dic = dict.fromkeys(n_vals, 0)
# loop over n_vals
for n in n_vals:
    results = pd.DataFrame(columns = ['itrial','d','method','coverage','width'])
    Xa = np.zeros((n, ntrial))
    Ya = np.zeros((n, ntrial))
    for itrial in range(ntrial):
        X = np.random.normal(size=(n,d))
        Xa[:, itrial] = X[:,0]
        Y = X.dot(beta) + np.random.normal(size=n)
        Ya[:, itrial] = Y
        # store X, Y for later use with R code
        # store as numpy arrays
        PIs = compute_PIs(X = X, Y = Y, X1 = X1)
        coverage = ((PIs[method]['lower'] <= Y1)&(PIs[method]['upper'] >= Y1)).mean()
        width = (PIs[method]['upper'] - PIs[method]['lower']).mean()
        results.loc[len(results)]=[itrial,d,method,coverage,width]
    X_dic[n] = Xa
    Y_dic[n] = Ya
```

```{r, get_python_results, eval = FALSE}
saveRDS(py$PIs, file = "PIs.rds")
```



```{r, eval = TRUE}
res_list <- list()
vars_list_list_list() <- list()
n_folds_vec <- c(5, 10, 20, 50)
for (n_folds in n_folds_vec){
    # partition training data into K folds
    folds <- split(training$id, sample(rep(1:n_folds, length.out = n_tr)))
    training2_pre <- training %>% 
        dplyr::mutate(fold = id %>% purrr::map_int(~which(sapply(folds, function(x) . %in% x)))) %>%
        dplyr::arrange(fold)
    tictoc::tic() # timing
    tl <- list()
    n_per_fold_vec <- c(n_tr / n_folds, n_tr / (n_folds * 10))
    vars_list_list <- list()
    for (n_per_fold in n_per_fold_vec){
        training2 <- training2_pre %>%
            dplyr::group_by(fold) %>%
            dplyr::slice_sample(n = n_per_fold) %>%
            dplyr::ungroup()
        # store each trait's outputs
        out <- list()
        vars_list <- list()
        # loop over traits
        for (trait_num in 1:n_reps){
            tr2_one_trait <- training2 %>%
                dplyr::select(id, fold, geno, tidyselect::ends_with(paste0("pheno", trait_num))) %>%
                dplyr::rename(pheno = tidyselect::ends_with(paste0("pheno", trait_num)))
            te2_one_trait <- testing2 %>%
                dplyr::select(id, fold, geno, tidyselect::ends_with(paste0("pheno", trait_num))) %>%
                dplyr::rename(pheno = tidyselect::ends_with(paste0("pheno", trait_num)))
            
            # regress leaving one fold out
            preds <- list()
            vars <- list()
            for (fold_num in 1:n_folds) {
                # get training data
                train <- tr2_one_trait %>% dplyr::filter(fold != fold_num)
                # get testing data
                test <- tr2_one_trait %>% dplyr::filter(fold == fold_num)
                # fit model
                fit <- lm(pheno ~ 1 + geno, data = train)
                # predict
                foo <- test %>% dplyr::bind_rows(te2_one_trait)
                foo$pred <- predict(fit, newdata = foo)
                foo$fold_left_out <- fold_num
                result <- foo %>%
                    dplyr::mutate(beta1_hat = coef(fit)[2],
                                beta0_hat = coef(fit)[1],
                                se_beta1_hat = summary(fit)$coefficients[2, 2],
                                se_beta0_hat = summary(fit)$coefficients[1, 2]
                    )
                # save predictions
                preds[[fold_num]] <- result
                te_geno_mat <- cbind(1, te2_one_trait$geno)
                tr_geno_mat <- cbind(1, train$geno)
                vars[[fold_num]] <- diag(te_geno_mat %*% solve(t(tr_geno_mat) %*% tr_geno_mat) %*% t(te_geno_mat))
            }
            vars_list[[trait_num]] <- vars
            # assemble predicted values
            # get absolute residuals
            preds_training <- preds %>%
                dplyr::bind_rows() %>%
                dplyr::filter(!is.na(fold)) %>% # keep only training data
                dplyr::mutate(absolute_residual = abs(pheno - pred)) %>%
                dplyr::select( - fold_left_out)
            preds_test <- preds %>%
                dplyr::bind_rows() %>%
                dplyr::filter(is.na(fold))
            # get indexes
            plus_index <- ceiling((1 - alpha) * (nrow(preds_training) + 1))
            minus_index <- floor(alpha * (nrow(preds_training) + 1))
        
            # go one by one through test set (testing2)
            test_list <- list()
            for (i in 1:nrow(testing2)){
                tt <- testing2[i, ]
                pt2 <- preds_test %>% 
                    dplyr::filter(id == tt$id) %>% # our only use of tt
                    dplyr::rename_with(function(x)paste0("test_", x)) 
                    # pt2 contains the five predicted values for a single test subject
                nrow(pt2) # 5
                preds_all <- preds_training %>%
                    dplyr::left_join(pt2, by = c("fold" = "test_fold_left_out")) %>%
                    dplyr::mutate(test_fitted_plus_absolute_residual = test_pred + absolute_residual, 
                                test_fitted_minus_absolute_residual = test_pred - absolute_residual) 
                uu <- sort(preds_all$test_fitted_plus_absolute_residual)[plus_index]
                ll <- sort(preds_all$test_fitted_minus_absolute_residual)[minus_index]
                # make a tibble with exactly one row
                test_list[[i]] <- preds_all %>%
                    dplyr::select(test_id, test_geno, test_pheno, test_beta1_hat, fold) %>%
                    dplyr::mutate(lower = ll, upper = uu) %>%
                    dplyr::distinct() %>%
                    tidyr::pivot_wider(names_from = fold, 
                                        values_from = test_beta1_hat,
                                        names_prefix = "beta1_hat_fold_"
                                        )
            }
            test_tib <- test_list %>%
                dplyr::bind_rows() %>%
                dplyr::mutate(in_interval = test_pheno >= lower & test_pheno <= upper) %>%
                dplyr::mutate(interval_width = upper - lower) %>%
                dplyr::mutate(training_set_size = n_per_fold * n_folds,
                                trait_num = trait_num)
            out[[trait_num]] <- test_tib
        }
        tl[[as.character(n_per_fold * n_folds)]]  <- out
        vars_list_list[[as.character(n_per_fold * n_folds)]] <- vars_list
    }
    res_list[[as.character(n_folds)]] <- tl
    vars_list_list_list[[as.character(n_folds)]] <- vars_list_list
    tictoc::toc() # timing
}
saveRDS(res_list, "res_list.rds")
saveRDS(vars_list_list_list, "vars_list_list_list.rds")
```

## Organize results


```{r, results = "asis", eval = TRUE}
#test_tib_thin <- test_tib %>%
#    dplyr::select(test_id, test_geno)
tt_intermediate <- tl %>%
    dplyr::bind_rows(.id = "id") 
results <- tt_intermediate %>%
    dplyr::group_by(training_set_size, trait_num) %>%
    dplyr::summarise(mean_interval_width = mean(interval_width),
                    sd_interval_width = sd(interval_width),
                    mean_in_interval = mean(in_interval),
                    sd_in_interval = sd(in_interval), 
                    beta1_hat_fold_1 = mean(beta1_hat_fold_1),
                    beta1_hat_fold_2 = mean(beta1_hat_fold_2),
                    beta1_hat_fold_3 = mean(beta1_hat_fold_3),
                    beta1_hat_fold_4 = mean(beta1_hat_fold_4),
                    beta1_hat_fold_5 = mean(beta1_hat_fold_5),
                    median_interval_width = median(interval_width)
                    ) %>%
                    dplyr::ungroup() %>%
                    dplyr::mutate(mean_b1 = purrr::pmap_dbl(.l = list(beta1_hat_fold_1,
                                                                        beta1_hat_fold_2, 
                                                                        beta1_hat_fold_3, 
                                                                        beta1_hat_fold_4,
                                                                         beta1_hat_fold_5), 
                                                           .f = function(x, y, z, w, v) mean(c(x, y, z, w, v))),
                                    sd_b1 = purrr::pmap_dbl(.l = list(beta1_hat_fold_1,
                                                                        beta1_hat_fold_2, 
                                                                        beta1_hat_fold_3, 
                                                                        beta1_hat_fold_4,
                                                                         beta1_hat_fold_5), 
                                                           .f = function(x, y, z, w, v) sd(c(x, y, z, w, v)))
                    ) 
results %>%
    knitr::kable() %>%
    print()

```


## Figures

### Boxplots for interval width

```{r, eval = TRUE}
library(ggplot2)
tt_intermediate %>%
    ggplot(aes(y = interval_width, colour = as.factor(training_set_size), x = as.factor(trait_num)))  +
    geom_boxplot()
#ggsave(here::here("figures", "interval_width_boxplot.png"), width = 10, height = 10)
```

### Relationship between $\hat\beta$ and median interval width

```{r, eval = TRUE}
p1 <- results %>%
    ggplot(aes(x = mean_b1, y = median_interval_width, colour = as.factor(training_set_size), replicate_num = trait_num)) +
    geom_point()
plotly::ggplotly(p1, tooltip = c("x", "y", "colour", "replicate_num"))
```



## Session Info

```{r, session_info}
sessioninfo::session_info()
# git commit info
gr <- git2r::repository(here::here()) %>%
    git2r::commits()
gr[[1]] 
```
